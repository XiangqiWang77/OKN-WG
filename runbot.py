import os
import streamlit as st
import json
from io import BytesIO
from PIL import Image
import requests
from dotenv import load_dotenv
from neo4j import GraphDatabase
from openai import OpenAI
from toolbox.chains import configure_llm_only_chain, prompt_cypher, configure_qa_rag_chain, generate_llava_output, classfic, web_agent_multimedia
from toolbox.utils import ImageDownloader, convert_to_base64
from toolbox.aspects import generate_aspect_chain, extract_keywords_from_question
from toolbox.web_agent import web_search_agent, infer_node_scope_from_question 

# åŠ è½½ç¯å¢ƒå˜é‡
#load_dotenv(".env")

# Neo4j æ•°æ®åº“é…ç½®
NEO4J_URI=st.secrets["NEO4J_URI"]
NEO4J_USER="neo4j"
NEO4J_PASSWORD=st.secrets["NEO4J_PASSWORD"]
driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

# OpenAI é…ç½®
api_key = st.secrets["OPENAI_KEY"]
client = OpenAI(api_key=api_key)

# åŠ è½½ aspect åˆ†ç±»çš„ JSON æ•°æ®
with open('aspects.json', 'r') as f:
    json_data = json.load(f)

# è°ƒç”¨ OpenAI ç”Ÿæˆå›ç­”
def send_openai_prompt(prompt_text, model_name="gpt-4o", temperature=0.7):
    try:
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt_text}],
            model=model_name,
            temperature=temperature,
            #max_tokens=token_limit
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"Request failed: {e}"

# è‡ªåŠ¨è¡¥å…¨é—®é¢˜
def get_autocomplete_suggestions(question):
    prompt = f"""
    You are given a graph containing information about animals and locations in Florida. Complete the user's partially entered question.
    Input: {question}
    """
    return send_openai_prompt(prompt)

# LLMåŠ è½½
def load_llm(llm_name: str):
    return lambda prompt: send_openai_prompt(prompt, model_name=llm_name)

llm = load_llm("gpt-4o")

# æ‰§è¡Œ Neo4j æŸ¥è¯¢
def query_neo4j(cypher_query, params=None):
    with driver.session() as session:
        result = session.run(cypher_query, params or {})
        return [record for record in result]

# å¤„ç†å›¾åƒä¸‹è½½å’Œå±•ç¤º
def display_images(urls):
    if not urls:
        st.write("No images available.")
        return

    cols = st.columns(len(urls))
    for i, url in enumerate(urls):
        try:
            # è®¾ç½® User-Agent å’Œ Referer
            headers = {
                "User-Agent": "MyImageFetcher/1.0 (https://wildlifelookup.streamlit.app/; xwang76@nd.edu)",
                "Referer": "https://www.wikimedia.org/"
            }

            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()

            # æ£€æŸ¥ Content-Type
            content_type = response.headers.get("Content-Type", "")
            if not content_type.startswith("image/"):
                raise ValueError(f"URL does not point to an image: {url}")

            # æ˜¾ç¤ºå›¾ç‰‡
            image = Image.open(BytesIO(response.content)).convert("RGB")
            cols[i].image(image, caption=f"Image {i+1}", use_column_width=True)
        except Exception as e:
            # è·³è¿‡æ— æ³•åŠ è½½çš„å›¾ç‰‡
            cols[i].write(f"Failed to load image {i+1}: {e}")



# å¤„ç†èŠå¤©è¾“å…¥
def chat_input():
    user_input_text = st.text_input("What do you want to know about wildlife in the US?", key="user_input_text", value="")
    if user_input_text:
        suggestion = get_autocomplete_suggestions(user_input_text)
        st.markdown(f"**Suggestion:** {suggestion}")

        if st.button("Accept Suggestion"):
            user_input_text = suggestion
        
        response = llm(user_input_text)
        with st.chat_message("assistant"):
            st.write(response)

# RAGæ¨¡å¼é€‰æ‹©
def mode_select() -> list:
    options = ["Regular Response", "AI as Translator to KN-Wildlife", "AI as Toolbox for Aspect-Based Question", "AI as a Online(Wikidata) Searching Agent"]
    multimediaoptions = ["Text Only", "Text and Images"]

    selected_multimedia_mode = st.radio("Select output mode", multimediaoptions, horizontal=True)
    mode_selected = st.radio("Select external sources", options, horizontal=True)
    
    return [mode_selected, selected_multimedia_mode]

def extract_keywords_from_response(response_text):
    """
    Extracts important keywords or entities from the LLM-generated response using OpenAI GPT.
    """
    # Prompt for LLM to extract keywords
    prompt = f"""
    Extract the top 5 most relevant keywords or entities from the following text.
    Focus on nouns, names, or important terms relevant to the context.

    Text: {response_text}

    Return the keywords as a Python list of strings.
    """

    try:
        # Call the LLM API to process the prompt
        keywords_response = send_openai_prompt(prompt, model_name="gpt-4", temperature=0.5)

        # Ensure the result is a Python list (convert string output to Python object)
        keywords = eval(keywords_response.strip())
        return keywords

    except Exception as e:
        print(f"Error extracting keywords: {e}")
        return []  # Fallback to an empty list if extraction fails

def get_wikidata_id(entity_name):
    """
    Retrieves the Wikidata entity ID for a given entity name using Wikidata API.
    """
    url = "https://www.wikidata.org/w/api.php"
    params = {
        "action": "wbsearchentities",
        "language": "en",
        "format": "json",
        "search": entity_name
    }

    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        data = response.json()

        if data.get('search'):
            # Return the first matching ID with the highest relevance
            return data['search'][0]['id']
    except Exception as e:
        print(f"Error fetching Wikidata ID for '{entity_name}': {e}")
    
    return None  # Return None if no entity ID is found

def validate_image_url(url, headers):
    """
    éªŒè¯å›¾ç‰‡ URL æ˜¯å¦æœ‰æ•ˆã€‚
    è¿”å› True å¦‚æœ URL æŒ‡å‘æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶ï¼Œå¦åˆ™è¿”å› Falseã€‚
    """
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        # æ£€æŸ¥ Content-Type æ˜¯å¦ä»¥ image/ å¼€å¤´
        content_type = response.headers.get("Content-Type", "")
        if content_type.startswith("image/"):
            return True
    except Exception as e:
        print(f"Error validating image URL '{url}': {e}")
    return False


def search_images_from_keywords(keywords):
    """
    ä½¿ç”¨ Wikidata çš„ SPARQL æŸ¥è¯¢ç«¯ç‚¹ï¼Œæ ¹æ®æå–çš„å…³é”®è¯æœç´¢å›¾ç‰‡ã€‚
    è¿”å›æœ‰æ•ˆçš„å›¾ç‰‡ URL åˆ—è¡¨ï¼Œè‡ªåŠ¨è·³è¿‡åŠ è½½å¤±è´¥çš„å›¾ç‰‡ã€‚
    """
    image_urls = []
    wikidata_sparql_endpoint = "https://query.wikidata.org/sparql"

    for keyword in keywords[:5]:
        # Step 1: è·å–å…³é”®è¯çš„ Wikidata å®ä½“ ID
        entity_id = get_wikidata_id(keyword)
        if not entity_id:
            continue  # å¦‚æœæ‰¾ä¸åˆ°å®ä½“ IDï¼Œè·³è¿‡æ­¤å…³é”®è¯

        # Step 2: æ„å»º SPARQL æŸ¥è¯¢ï¼ŒæŸ¥æ‰¾å®ä½“çš„å›¾ç‰‡ï¼ˆP18 å±æ€§ï¼‰
        query = f"""
        SELECT ?image WHERE {{
          wd:{entity_id} wdt:P18 ?image.
        }}
        LIMIT 1
        """

        # è®¾ç½® User-Agent å¤´éƒ¨ï¼Œç¡®ä¿ç¬¦åˆ Wikidata çš„ç”¨æˆ·ä»£ç†ç­–ç•¥
        headers = {
            "User-Agent": "MyImageFetcher/1.0 (https://wildlifelookup.streamlit.app/; xwang76@nd.edu)"
        }

        try:
            # å‘é€è¯·æ±‚
            response = requests.get(
                wikidata_sparql_endpoint,
                params={"query": query, "format": "json"},
                headers=headers
            )
            response.raise_for_status()
            data = response.json()

            # ä»è¿”å›çš„æ•°æ®ä¸­æå–å›¾ç‰‡ URL
            for result in data["results"]["bindings"]:
                if "image" in result:
                    image_url = result["image"]["value"]

                    # æµ‹è¯•å›¾ç‰‡ URL æ˜¯å¦æœ‰æ•ˆ
                    if validate_image_url(image_url, headers):
                        image_urls.append(image_url)
                    else:
                        print(f"Invalid image URL (skipped): {image_url}")

        except Exception as e:
            print(f"Error fetching image for keyword '{keyword}': {e}")

    return image_urls




# å¤„ç†ä¸åŒæ¨¡å¼ä¸‹çš„é€»è¾‘
def handle_chat_mode(name, user_input):
    print(name[0])
    result = None

    if name[0] == "Regular Response":
        if name[1] == "Text Only":
            result = configure_llm_only_chain(user_input)
        elif name[1] == "Text and Images":
            # Step 1: Generate the textual response
            result = configure_llm_only_chain(user_input)

            # Step 2: Extract keywords/entities from the generated text
            keywords = extract_keywords_from_response(result)

            # Step 3: Search for images based on the extracted keywords
            image_urls = search_images_from_keywords(keywords)

            # Step 4: Display images if available
            if image_urls:
                display_images(image_urls)
            else:
                st.write("No images found for the extracted keywords.")

    elif name[0] == "AI as Translator to KN-Wildlife":
        translate_function = prompt_cypher(llm)  # è·å–ç”Ÿæˆå‡½æ•°
        temp_result = translate_function(user_input)  # è°ƒç”¨ç”Ÿæˆå‡½æ•°è·å– Cypher æŸ¥è¯¢

        print(temp_result)  # æ£€æŸ¥ Cypher æŸ¥è¯¢æ˜¯å¦æ­£ç¡®ç”Ÿæˆ

        if name[1] == "Text Only":
            rag_chain = configure_qa_rag_chain(
                llm,  # ç¬¬ä¸€ä¸ªå‚æ•°ä¼ é€’ llm
                query=temp_result,  # ä¼ é€’ç”Ÿæˆçš„ Cypher æŸ¥è¯¢
                Graph_url=NEO4J_URI,
                username=NEO4J_USER,
                password=NEO4J_PASSWORD
            )
            result = rag_chain

        elif name[1] == "Text and Images":
            # æ‰§è¡Œå›¾è°±æŸ¥è¯¢
            kg_output = query_neo4j(temp_result)

            print("kg_output", kg_output)

            # ä½¿ç”¨LLaVAè¾“å‡ºå¤„ç†å¤šåª’ä½“æ•°æ®
            feed_result = generate_llava_output(user_input, kg_output)
            result = feed_result["answer"]

            # å±•ç¤ºå¤šåª’ä½“ï¼ˆå›¾ç‰‡ç­‰ï¼‰
            keywords = extract_keywords_from_response(result)

            # Step 3: Search for images based on the extracted keywords
            image_urls = search_images_from_keywords(keywords)

            # Step 4: Display images if available
            if image_urls:
                display_images(image_urls)
            else:
                st.write("No images found for the extracted keywords.")

    elif name[0] == "AI as Toolbox for Aspect-Based Question":
        aspect_category = classfic(user_input, json_data, llm)
        temp_chain = generate_aspect_chain(
            question=user_input,
            multimedia_option=name[1],
            aspect=aspect_category,
            llm_name=llm,
            vllm_name=None
        )
        feed_result = temp_chain

        if name[1] == "Text Only":
            result = feed_result["answer"]
        elif name[1] == "Text and Images":
            result = feed_result["answer"]
            keywords = extract_keywords_from_response(result)

            # Step 3: Search for images based on the extracted keywords
            image_urls = search_images_from_keywords(keywords)

            # Step 4: Display images if available
            if image_urls:
                display_images(image_urls)
            else:
                st.write("No images found for the extracted keywords.")

    elif name[0] == "AI as a Online(Wikidata) Searching Agent":
        print("Function calling")

        # é€šè¿‡ LLM æ¨æ–­å¯èƒ½çš„èŠ‚ç‚¹èŒƒå›´
        node_scope = infer_node_scope_from_question(llm, user_input)

        # æ‰§è¡Œ web search agentï¼Œä¼ é€’èŠ‚ç‚¹èŒƒå›´é™åˆ¶
        agent_result = web_search_agent(
            llm=llm,
            question=user_input,
            node_scope=node_scope  # ä¼ é€’èŠ‚ç‚¹èŒƒå›´
        )

        # æ‹¼æ¥æœ€ç»ˆæŸ¥è¯¢
        Final_str = (
            f"question is {user_input} The web retrieval agent is {agent_result} "
            "Please provide an answer."
        )

        print(Final_str)

        if name[1] == "Text Only":
            result = send_openai_prompt(Final_str)
        elif name[1] == "Text and Images":
            result = send_openai_prompt(Final_str)
            # Add logic to process multimedia retrieval if required
            # Step 2: Extract keywords/entities from the generated text
            keywords = extract_keywords_from_response(result)

            # Step 3: Search for images based on the extracted keywords
            image_urls = search_images_from_keywords(keywords)

            # Step 4: Display images if available
            if image_urls:
                display_images(image_urls)
            else:
                st.write("No images found for the extracted keywords.")

    # å¢åŠ å…œåº•æœºåˆ¶
    if result is None:
        result = "No result generated. Please refine your question or try a different mode."

    return result

import time
from streamlit_modal import Modal  # ä½¿ç”¨ `streamlit-modal` æ’ä»¶å®ç°å¼¹å‡ºæ¡†
import threading
def keep_neo4j_alive(interval=300):
    def query():
        with driver.session() as session:
            try:
                session.run("MATCH (n) RETURN count(n) LIMIT 1")
                print("Keep-alive query sent to Neo4j.")
            except Exception as e:
                print(f"Neo4j keep-alive query failed: {e}")

    while True:
        query()
        time.sleep(interval)

# ä¿æŒ Streamlit åº”ç”¨çš„è¿è¡Œ
def keep_streamlit_alive():
    while True:
        time.sleep(1)
        st.experimental_rerun()

# åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨ keep-alive åŠŸèƒ½
def start_keep_alive_tasks():
    # å¯åŠ¨ Neo4j ä¿æ´»çº¿ç¨‹
    neo4j_thread = threading.Thread(target=keep_neo4j_alive, daemon=True)
    neo4j_thread.start()

    # å¯åŠ¨ Streamlit ä¿æ´»çº¿ç¨‹
    streamlit_thread = threading.Thread(target=keep_streamlit_alive, daemon=True)
    streamlit_thread.start()

# åˆå§‹åŒ–ä¿æ´»ä»»åŠ¡
if "keep_alive_started" not in st.session_state:
    start_keep_alive_tasks()
    st.session_state["keep_alive_started"] = True

# é¡µé¢å¸ƒå±€
st.title("Wildlife Knowledge Assistant ğŸ¾")
st.write("A bot to assist you with wildlife knowledge and Neo4j-powered queries.")

# åˆ›å»ºå¼¹å‡ºæ¡†ä»‹ç»åŠŸèƒ½
def show_bot_introduction():
    modal = Modal(key="introduction_modal", title="Meet Your Wildlife Knowledge Assistant!")
    if modal.open:
        with modal.container():
            st.markdown("""
            ### Welcome to Wildlife Knowledge Assistant ğŸ¾
            This bot is designed to help you:
            - Query and visualize wildlife-related data using **Neo4j**.
            - Ask complex questions and receive detailed answers powered by **LLM**.
            - Explore multimedia (text and images) information related to your questions.
            - Discover more about wildlife in the United States and beyond.

            **Features**:
            - **Interactive Modes**: Choose from various response modes (text-only, multimedia, etc.).
            - **Custom AI Models**: Powered by GPT-based LLMs and integrated APIs for a rich experience.
            - **Neo4j Database**: Provides real-time data querying and visualization.

            **How to use**:
            1. Type your question in the input box.
            2. Select a mode and hit submit.
            3. Explore the detailed results with optional images.

            We hope you enjoy exploring the wildlife knowledge base! ğŸŒ¿
            """)
            st.image("https://upload.wikimedia.org/wikipedia/commons/3/32/Nature-Wildlife.jpg", use_column_width=True)

# åˆ›å»ºä¸€ä¸ªæŒ‰é’®è§¦å‘å¼¹å‡ºæ¡†
st.sidebar.markdown("### ğŸ” Bot Info")
if st.sidebar.button("What is this bot?"):
    show_bot_introduction()

# é¡µé¢åˆå§‹åŒ–
#st.title("Wildlife Knowledge Assistant")

name = mode_select()
user_input_text = st.text_input("What would you like to know?")

if user_input_text:
    result = handle_chat_mode(name, user_input_text)
    st.write(result)
